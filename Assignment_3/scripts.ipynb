{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xmltodict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/thesnagtalker007/Documents/GitHub/Advanced-CompArch/Assignment_3/scripts.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/thesnagtalker007/Documents/GitHub/Advanced-CompArch/Assignment_3/scripts.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mxmltodict\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/thesnagtalker007/Documents/GitHub/Advanced-CompArch/Assignment_3/scripts.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/thesnagtalker007/Documents/GitHub/Advanced-CompArch/Assignment_3/scripts.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnotebook\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xmltodict'"
     ]
    }
   ],
   "source": [
    "import xmltodict\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file = 'config_tigerLake.xml'\n",
    "with open(xml_file, 'r') as file:\n",
    "    xml_data = file.read()\n",
    "\n",
    "xml_dict = xmltodict.parse(xml_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stat File Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'L1d Hit rate': '0.9544035',\n",
       " 'L1i Hit rate': '0.79096586',\n",
       " 'L2 Hit rate': '0.9847691',\n",
       " 'L3 Hit rate': '0.20170666',\n",
       " 'L1i TLB hit rate': '0.9988',\n",
       " 'L1d TLB hit rate': '0.9954',\n",
       " 'IPC': '1.7945',\n",
       " 'Branch Prediction Accuracy': '89.7722',\n",
       " 'Time Taken': '2228 ',\n",
       " 'Micro-op Cache Hit Rate': '0.8279',\n",
       " 'Target Predictor Accuracy': '82.4859',\n",
       " 'Predicate Predictor Accuracy': '97.4274'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_stats(stat_file):\n",
    "    # Read the configuration file\n",
    "    with open(stat_file, \"r\") as file:\n",
    "        config_data = file.read()\n",
    "\n",
    "    # Define regex patterns for each metric\n",
    "    l1d_hit_rate_pattern = r\"L1\\[0\\] Hit-Rate\\s*=\\s*([\\d.]+)\"\n",
    "    l1i_hit_rate_pattern = r\"I1\\[0\\] Hit-Rate\\s*=\\s*([\\d.]+)\"\n",
    "    l2_hit_rate_pattern = r\"L2\\[0\\] Hit-Rate\\s*=\\s*([\\d.]+)\"\n",
    "    l3_hit_rate_pattern = r\"L3\\[0\\] Hit-Rate\\s*=\\s*([\\d.]+)\"\n",
    "    l1i_tlb_hit_rate_pattern = r\"iTLB\\[0\\] Hit-Rate\\s*=\\s*([\\d.]+)\"\n",
    "    l1d_tlb_hit_rate_pattern = r\"dTLB\\[0\\] Hit-Rate\\s*=\\s*([\\d.]+)\"\n",
    "    ipc_pattern = r\"IPC\\s*=\\s*([\\d.]+)\\s+in terms of micro-ops\"\n",
    "    branch_prediction_accuracy_pattern = r\"branch predictor accuracy\\s*=\\s*([\\d.]+)\"\n",
    "    total_execution_time_pattern = r\"Total Execution Time\\s*=\\s*([\\d\\s:]+)\"\n",
    "    micro_op_cache_hit_rate_pattern = r\"micro-op cache hit rate\\s*=\\s*([\\d.]+)\"\n",
    "    target_predictor_accuracy_pattern = r\"target predictor accuracy\\s*=\\s*([\\d.]+)\"\n",
    "    predicate_predictor_accuracy_pattern = r\"predicate predictor accuracy\\s*=\\s*([\\d.]+)\"\n",
    "    \n",
    "    core_energy_pattern = r\"^coreEnergy.total*\"\n",
    "    shared_cache_energy_pattern = r\"sharedCacheEnergy.total\\s*=\\s*([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\"\n",
    "    main_memory_energy_pattern = r\"mainMemoryControllerEnergy.total\\s*=\\s*([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\"\n",
    "    coherence_energy_pattern = r\"coherenceEnergy.total\\s*=\\s*([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\"\n",
    "    total_energy_pattern = r\"TotalEnergy\\s*=\\s*([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\\s+([\\d.]+)\"\n",
    "\n",
    "    # Function to extract a metric using the given pattern\n",
    "    def extract_metric(pattern, data):\n",
    "        match = re.search(pattern, data)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        return None\n",
    "\n",
    "    # Extract metrics from the configuration data\n",
    "    l1d_hit_rate = extract_metric(l1d_hit_rate_pattern, config_data)\n",
    "    l1i_hit_rate = extract_metric(l1i_hit_rate_pattern, config_data)\n",
    "    l2_hit_rate = extract_metric(l2_hit_rate_pattern, config_data)\n",
    "    l3_hit_rate = extract_metric(l3_hit_rate_pattern, config_data)\n",
    "    l1i_tlb_hit_rate = extract_metric(l1i_tlb_hit_rate_pattern, config_data)\n",
    "    l1d_tlb_hit_rate = extract_metric(l1d_tlb_hit_rate_pattern, config_data)\n",
    "    ipc = extract_metric(ipc_pattern, config_data)\n",
    "    branch_prediction_accuracy = extract_metric(branch_prediction_accuracy_pattern, config_data)\n",
    "    time_taken = extract_metric(total_execution_time_pattern, config_data)\n",
    "    micro_op_cache_hit_rate = extract_metric(micro_op_cache_hit_rate_pattern, config_data)\n",
    "    target_predictor_accuracy = extract_metric(target_predictor_accuracy_pattern, config_data)\n",
    "    predicate_predictor_accuracy = extract_metric(predicate_predictor_accuracy_pattern, config_data)\n",
    "    core_energy = extract_metric(core_energy_pattern, config_data)\n",
    "    print(core_energy)\n",
    "    # shared_cache_energy = tuple(map(float, extract_metric(shared_cache_energy_pattern, config_data).split()))\n",
    "    # main_memory_energy = tuple(map(float, extract_metric(main_memory_energy_pattern, config_data).split()))\n",
    "    # coherence_energy = tuple(map(float, extract_metric(coherence_energy_pattern, config_data).split()))\n",
    "    # total_energy = tuple(map(float, extract_metric(total_energy_pattern, config_data).split()))\n",
    "\n",
    "    # Print the extracted metrics\n",
    "    data = {\n",
    "        \"L1d Hit rate\": l1d_hit_rate,\n",
    "        \"L1i Hit rate\": l1i_hit_rate,\n",
    "        \"L2 Hit rate\": l2_hit_rate,\n",
    "        \"L3 Hit rate\": l3_hit_rate,\n",
    "        \"L1i TLB hit rate\": l1i_tlb_hit_rate,\n",
    "        \"L1d TLB hit rate\": l1d_tlb_hit_rate,\n",
    "        \"IPC\": ipc,\n",
    "        \"Branch Prediction Accuracy\": branch_prediction_accuracy,\n",
    "        \"Time Taken\": time_taken,\n",
    "        \"Micro-op Cache Hit Rate\": micro_op_cache_hit_rate,\n",
    "        \"Target Predictor Accuracy\": target_predictor_accuracy,\n",
    "        \"Predicate Predictor Accuracy\": predicate_predictor_accuracy,\n",
    "        # \"Core Energy\": core_energy,\n",
    "        # \"Shared Cache Energy\": shared_cache_energy,\n",
    "        # \"Main Memory Controller Energy\": main_memory_energy,\n",
    "        # \"Coherence Energy\": coherence_energy,\n",
    "        # \"Total Energy\": total_energy,\n",
    "    }\n",
    "    return data\n",
    "\n",
    "extract_stats('gcc.stat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jar_file = \"/home/shashankp/Desktop/GitHub_S/Advanced-CompArch/cs810_resources/Tejas/jars/tejas.jar\"\n",
    "config_path = \"./config_tigerLake.xml\"\n",
    "benchmarks = ['gcc', 'lbm', 'mcf', 'namd', 'xalancbmk']\n",
    "specifications = {\n",
    "    \"Predictor_Mode\": ['AlwaysNotTaken', 'PerfectPredictor', 'BranchPredictor', 'PAgPredictor', 'GApPredictor', 'TournamentPredictor', 'NoPredictor', 'BTB', 'GShare', 'AlwaysTaken', 'TAGE-SC-L', 'GAgpredictor', 'PApPredictor', 'BimodalPredictor', 'TAGE'],\n",
    "    \"MainMemoryLatency\": [10, 50, 100, 500],\n",
    "    \"CoreFrequency\": [100, 500, 2000, 5000],\n",
    "    \"BHRsize\": [2, 4, 8, 16, 32, 64],\n",
    "    \"MainMemoryFrequency\": [100, 500, 2000, 5000],\n",
    "    \"ITLB-Size\": [10, 50, 200, 500], \n",
    "    \"DTLB-Size\": [10, 50, 200, 500],\n",
    "    \"NumberOfMicroOps\": [500, 1000, 2000, 5000],\n",
    "    \"IntRegFileSize\": [50, 100, 200, 400],\n",
    "    \"VectorRegFileSize\": [50, 100, 200, 400],\n",
    "    \"IntDiv-Latency\": [1, 10, 20],\n",
    "    \"IntVectorMul-Latency\": [1, 5, 10, 20],\n",
    "    \"FloatMul-Latency\": [1, 5, 10, 20],\n",
    "    \"FloatDiv-Latency\": [1, 5, 10, 20],    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_config_file(old_file, new_file, key, value):\n",
    "    import xml.etree.ElementTree as ET\n",
    "\n",
    "    def change_element_recursive(root, element_name):\n",
    "        # Check if the current element's tag matches the desired element name\n",
    "        if root.tag == element_name:\n",
    "            return root\n",
    "\n",
    "        # Recursively search through child elements\n",
    "        for child in root:\n",
    "            found_element = change_element_recursive(child, element_name)\n",
    "            if found_element is not None:\n",
    "                return found_element\n",
    "\n",
    "        # Element not found in this branch\n",
    "        return None\n",
    "\n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(old_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Call the recursive function to find the element\n",
    "    v = change_element_recursive(root, key,value)\n",
    "    v.text=value\n",
    "    if v is None:\n",
    "        print(\"Key doesn't exist\")\n",
    "\n",
    "    tree.write(new_file)\n",
    "\n",
    "# template : modify_config_file('config_tigerLake.xml','ht.xml','CommunicationType','bald')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_config_file_subtree(old_file, new_file, key1, key2, value):\n",
    "    import xml.etree.ElementTree as ET\n",
    "\n",
    "    def change_element_recursive(root, element_name):\n",
    "        # Check if the current element's tag matches the desired element name\n",
    "        if root.tag == element_name:\n",
    "            return root\n",
    "\n",
    "        # Recursively search through child elements\n",
    "        for child in root:\n",
    "            found_element = change_element_recursive(child, element_name)\n",
    "            if found_element is not None:\n",
    "                return found_element\n",
    "\n",
    "        # Element not found in this branch\n",
    "        return None\n",
    "\n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(old_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Call the recursive function to find the element\n",
    "    v = change_element_recursive(root, key1)\n",
    "    v1 = change_element_recursive(v, key2)\n",
    "    v1.text=value\n",
    "    if v is None:\n",
    "        print(\"Key doesn't exist\")\n",
    "\n",
    "    tree.write(new_file)\n",
    "\n",
    "modify_config_file_subtree('config_tigerLake.xml','ht1.xml','ITLB','Size','2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tejas Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tejas(benchmark, jar_file, config_file, stat_file):\n",
    "    bench_mark_path = f\"/home/shashankp/Desktop/GitHub_S/Advanced-CompArch/cs810_resources/CPU2017_benchmarks/tejas_traces/{benchmark}\"\n",
    "    command = (f'java -jar {jar_file} {config_file} {stat_file} {bench_mark_path}').split()\n",
    "    subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for benchmark in benchmarks:\n",
    "    for key in specifications:\n",
    "        total += len(specifications[key])\n",
    "pb = tqdm(total=total)\n",
    "\n",
    "full_result = dict()\n",
    "for benchmark in benchmarks:\n",
    "    full_result[benchmark] = {}\n",
    "    for key in specifications:\n",
    "        full_result[benchmark][key] = {}\n",
    "        for value in specifications[key]:\n",
    "            pb.update(1)\n",
    "            new_config = f\"./config/{benchmark}_{key}_{value}.xml\"\n",
    "            modify_config_file(config_path, new_config, key, value)\n",
    "            new_stat_file = f\"./stats/{benchmark}_{key}_{value}.stat\"\n",
    "            run_tejas(benchmark, jar_file, new_config, new_stat_file)\n",
    "            extracted_data = extract_stats(new_stat_file)\n",
    "# run_tejas('gcc', jar_file, config_path, './stats/gcc.stat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AlwaysNotTaken',\n",
       " 'PerfectPredictor',\n",
       " 'BranchPredictor',\n",
       " 'PAgPredictor',\n",
       " 'GApPredictor',\n",
       " 'TournamentPredictor',\n",
       " 'NoPredictor',\n",
       " 'BTB',\n",
       " 'GShare',\n",
       " 'AlwaysTaken',\n",
       " 'TAGESCL',\n",
       " 'GAgpredictor',\n",
       " 'PApPredictor',\n",
       " 'BimodalPredictor',\n",
       " 'TAGE']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "files = os.listdir('/home/shashankp/Desktop/GitHub_S/Advanced-CompArch/cs810_resources/Tejas/src/simulator/pipeline/branchpredictor')\n",
    "files = [file.split('.')[0] for file in files]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
