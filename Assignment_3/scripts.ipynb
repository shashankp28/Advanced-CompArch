{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xmltodict\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file = 'config_tigerLake.xml'\n",
    "with open(xml_file, 'r') as file:\n",
    "    xml_data = file.read()\n",
    "\n",
    "xml_dict = xmltodict.parse(xml_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stat File Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L1d Hit rate': 0.9544035,\n",
       " 'L1i Hit rate': 0.79096586,\n",
       " 'L2 Hit rate': 0.9847691,\n",
       " 'L3 Hit rate': 0.20170666,\n",
       " 'L1i TLB hit rate': 0.9988,\n",
       " 'L1d TLB hit rate': 0.9954,\n",
       " 'IPC': 1.7945,\n",
       " 'Branch Prediction Accuracy': 89.7722,\n",
       " 'Time Taken': 2228.0,\n",
       " 'Micro-op Cache Hit Rate': 0.8279,\n",
       " 'Target Predictor Accuracy': 82.4859,\n",
       " 'Predicate Predictor Accuracy': 97.4274,\n",
       " 'Core Energy': [390213428.5796, 15769978.6897, 405983407.2693, 0.0],\n",
       " 'Shared Cache Energy': [25300579.2864, 25024.6114, 25325603.8978, 0.0],\n",
       " 'Main Memory Controller Energy': [976185.1416, 1213.0112, 977398.1528, 0.0],\n",
       " 'Coherence Energy': [14602659.9264, 0.0, 14602659.9264, 0.0],\n",
       " 'Total Energy': [581692812.7244, 16138704.8587, 597831517.5831, 0.0]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_stats(stat_file):\n",
    "    # Read the configuration file\n",
    "    with open(stat_file, \"r\") as file:\n",
    "        config_data = file.read()\n",
    "\n",
    "    to_float = lambda lis: [float(x) for x in lis]\n",
    "    \n",
    "    # Define regex patterns for each metric\n",
    "    l1d_hit_rate_pattern = r\"L1\\[0\\] Hit-Rate\\s*=\\s*([\\d.]+)\"\n",
    "    l1i_hit_rate_pattern = r\"I1\\[0\\] Hit-Rate\\s*=\\s*([\\d.]+)\"\n",
    "    l2_hit_rate_pattern = r\"L2\\[0\\] Hit-Rate\\s*=\\s*([\\d.]+)\"\n",
    "    l3_hit_rate_pattern = r\"L3\\[0\\] Hit-Rate\\s*=\\s*([\\d.]+)\"\n",
    "    l1i_tlb_hit_rate_pattern = r\"iTLB\\[0\\] Hit-Rate\\s*=\\s*([\\d.]+)\"\n",
    "    l1d_tlb_hit_rate_pattern = r\"dTLB\\[0\\] Hit-Rate\\s*=\\s*([\\d.]+)\"\n",
    "    ipc_pattern = r\"IPC\\s*=\\s*([\\d.]+)\\s+in terms of micro-ops\"\n",
    "    branch_prediction_accuracy_pattern = r\"branch predictor accuracy\\s*=\\s*([\\d.]+)\"\n",
    "    total_execution_time_pattern = r\"Total Execution Time\\s*=\\s*([\\d\\s:]+)\"\n",
    "    micro_op_cache_hit_rate_pattern = r\"micro-op cache hit rate\\s*=\\s*([\\d.]+)\"\n",
    "    target_predictor_accuracy_pattern = r\"target predictor accuracy\\s*=\\s*([\\d.]+)\"\n",
    "    predicate_predictor_accuracy_pattern = r\"predicate predictor accuracy\\s*=\\s*([\\d.]+)\"\n",
    "\n",
    "    # Function to extract a metric using the given pattern\n",
    "    def extract_metric(pattern, data):\n",
    "        match = re.search(pattern, data)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        return None\n",
    "\n",
    "    # Extract metrics from the configuration data\n",
    "    l1d_hit_rate = extract_metric(l1d_hit_rate_pattern, config_data)\n",
    "    l1i_hit_rate = extract_metric(l1i_hit_rate_pattern, config_data)\n",
    "    l2_hit_rate = extract_metric(l2_hit_rate_pattern, config_data)\n",
    "    l3_hit_rate = extract_metric(l3_hit_rate_pattern, config_data)\n",
    "    l1i_tlb_hit_rate = extract_metric(l1i_tlb_hit_rate_pattern, config_data)\n",
    "    l1d_tlb_hit_rate = extract_metric(l1d_tlb_hit_rate_pattern, config_data)\n",
    "    ipc = extract_metric(ipc_pattern, config_data)\n",
    "    branch_prediction_accuracy = extract_metric(branch_prediction_accuracy_pattern, config_data)\n",
    "    time_taken = extract_metric(total_execution_time_pattern, config_data)\n",
    "    micro_op_cache_hit_rate = extract_metric(micro_op_cache_hit_rate_pattern, config_data)\n",
    "    target_predictor_accuracy = extract_metric(target_predictor_accuracy_pattern, config_data)\n",
    "    predicate_predictor_accuracy = extract_metric(predicate_predictor_accuracy_pattern, config_data)\n",
    "    core_energy = config_data.split(\"coreEnergy.total\")[1].split(\"\\n\")[0].strip().split()\n",
    "    shared_cache_energy = config_data.split(\"sharedCacheEnergy.total\")[1].split(\"\\n\")[0].strip().split()\n",
    "    main_memory_energy = config_data.split(\"mainMemoryControllerEnergy.total\")[1].split(\"\\n\")[0].strip().split()\n",
    "    coherence_energy = config_data.split(\"coherenceEnergy.total\")[1].split(\"\\n\")[0].strip().split()\n",
    "    total_energy = config_data.split(\"TotalEnergy\")[-1].split()\n",
    "\n",
    "    # Print the extracted metrics\n",
    "    data = {\n",
    "        \"L1d Hit rate\": float(l1d_hit_rate),\n",
    "        \"L1i Hit rate\": float(l1i_hit_rate),\n",
    "        \"L2 Hit rate\": float(l2_hit_rate),\n",
    "        \"L3 Hit rate\": float(l3_hit_rate),\n",
    "        \"L1i TLB hit rate\": float(l1i_tlb_hit_rate),\n",
    "        \"L1d TLB hit rate\": float(l1d_tlb_hit_rate),\n",
    "        \"IPC\": float(ipc),\n",
    "        \"Branch Prediction Accuracy\": float(branch_prediction_accuracy),\n",
    "        \"Time Taken\": float(time_taken),\n",
    "        \"Micro-op Cache Hit Rate\": float(micro_op_cache_hit_rate),\n",
    "        \"Target Predictor Accuracy\": float(target_predictor_accuracy),\n",
    "        \"Predicate Predictor Accuracy\": float(predicate_predictor_accuracy) if predicate_predictor_accuracy is not None else 0,\n",
    "        \"Core Energy\": to_float(core_energy),\n",
    "        \"Shared Cache Energy\": to_float(shared_cache_energy),\n",
    "        \"Main Memory Controller Energy\": to_float(main_memory_energy),\n",
    "        \"Coherence Energy\": to_float(coherence_energy),\n",
    "        \"Total Energy\": to_float(total_energy),\n",
    "    }\n",
    "    return data\n",
    "\n",
    "extract_stats('gcc.stat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "jar_file = \"/home/shashankp/Desktop/GitHub_S/Advanced-CompArch/cs810_resources/Tejas/jars/tejas.jar\"\n",
    "config_path = \"./config_tigerLake.xml\"\n",
    "benchmarks = ['gcc', 'lbm', 'mcf', 'namd', 'xalancbmk']\n",
    "specifications = {\n",
    "    \"BranchPredictor-Predictor_Mode\": [\"NoPredictor\", \"PerfectPredictor\", \"AlwaysTaken\", \"AlwaysNotTaken\", \"Tournament\", \"Bimodal\", \"GShare\", \"GAg\", \"GAp\", \"PAg\", \"PAp\", \"TAGE\", \"TAGE-SC-L\"],\n",
    "    \"MainMemory-MainMemoryLatency\": [10, 50, 100, 500],\n",
    "    \"Core-CoreFrequency\": [100, 500, 2000, 5000],\n",
    "    \"BranchPredictor-BHRsize\": [2, 4, 8, 16, 32, 64],\n",
    "    \"MainMemory-MainMemoryFrequency\": [100, 500, 2000, 5000],\n",
    "    \"ITLB-Size\": [10, 50, 200, 500], \n",
    "    \"DTLB-Size\": [10, 50, 200, 500],\n",
    "    \"IntVectorMul-Latency\": [1, 5, 10, 20],\n",
    "    \"FloatMul-Latency\": [1, 5, 10],\n",
    "    \"FloatALU-Latency\": [1, 5, 10],\n",
    "    \"FMA-Latency\": [1, 5, 10],\n",
    "}\n",
    "with open('command.txt', \"w+\") as file:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_config_file_subtree(old_file, new_file, key1, key2, value):\n",
    "    import xml.etree.ElementTree as ET\n",
    "    value = str(value)\n",
    "    def change_element_recursive(root, element_name):\n",
    "        # Check if the current element's tag matches the desired element name\n",
    "        if root.tag == element_name:\n",
    "            return root\n",
    "\n",
    "        # Recursively search through child elements\n",
    "        for child in root:\n",
    "            found_element = change_element_recursive(child, element_name)\n",
    "            if found_element is not None:\n",
    "                return found_element\n",
    "\n",
    "        # Element not found in this branch\n",
    "        return None\n",
    "\n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(old_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Call the recursive function to find the element\n",
    "    v = change_element_recursive(root, key1)\n",
    "    v1 = change_element_recursive(v, key2)\n",
    "    v1.text=value\n",
    "    if v is None:\n",
    "        print(\"Key doesn't exist\")\n",
    "\n",
    "    tree.write(new_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tejas Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tejas(benchmark, jar_file, config_file, stat_file):\n",
    "    bench_mark_path = f\"/home/shashankp/Desktop/GitHub_S/Advanced-CompArch/cs810_resources/CPU2017_benchmarks/tejas_traces/{benchmark}\"\n",
    "    command = (f'java -jar {jar_file} {config_file} {stat_file} {bench_mark_path}').split()\n",
    "    with open('command.txt', 'a') as file:\n",
    "        full_config_path = os.path.abspath(config_file)\n",
    "        command[3] = full_config_path\n",
    "        file.write(' '.join(command) + \"\\n\")\n",
    "    subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics(data, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd75ea2791b141dc982a8d5aa97dcc24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total = 0\n",
    "for benchmark in benchmarks:\n",
    "    for key in specifications:\n",
    "        total += len(specifications[key])\n",
    "pb = tqdm(total=total)\n",
    "\n",
    "full_result = dict()\n",
    "for benchmark in benchmarks:\n",
    "    full_result[benchmark] = {}\n",
    "    for key in specifications:\n",
    "        full_result[benchmark][key] = {}\n",
    "        key1, key2 = key.split('-')\n",
    "        for value in specifications[key]:\n",
    "            sleep(0.05)\n",
    "            new_config = f\"./config/{benchmark}_{key1}-{key2}_{value}.xml\"\n",
    "            new_stat_file = f\"./stats/{benchmark}_{key1}-{key2}_{value}.stat\"\n",
    "            if new_stat_file.split('/')[-1] in os.listdir('./stats'):\n",
    "                pb.update(1)\n",
    "                continue\n",
    "            modify_config_file_subtree(config_path, new_config, key1, key2, value)\n",
    "            run_tejas(benchmark, jar_file, new_config, new_stat_file)\n",
    "            extracted_data = extract_stats(new_stat_file)\n",
    "            save_metrics(extracted_data, f\"./metrics/{benchmark}_{key1}-{key2}_{value}.json\")\n",
    "            pb.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = \"./metrics/\"\n",
    "\n",
    "benchmarks = [\"gcc\", \"mcf\", \"namd\", \"lbm\", \"xalancbmk\"]\n",
    "\n",
    "suffixes = [\n",
    "    \"_BranchPredictor-BHRsize_\",\n",
    "    \"_BranchPredictor-Predictor_Mode_\",\n",
    "    \"_Core-CoreFrequency_\",\n",
    "    \"_DTLB-Size_\",\n",
    "    \"_FloatALU-Latency_\",\n",
    "    \"_FloatMul-Latency_\",\n",
    "    \"_FMA-Latency_\",\n",
    "    \"_IntVectorMul-Latency_\",\n",
    "    \"_ITLB-Size_\",\n",
    "    \"_MainMemory-MainMemoryFrequency_\",\n",
    "    \"_MainMemory-MainMemoryLatency_\"\n",
    "]\n",
    "\n",
    "size_maps = {\n",
    "    \"_BranchPredictor-BHRsize_\": [2, 4, 8, 16],\n",
    "    \"_BranchPredictor-Predictor_Mode_\": [\"AlwaysNotTaken\", \"AlwaysTaken\", \"Bimodal\", \"GAg\", \"GAp\", \"GShare\", \"NoPredictor\", \"PAg\", \"PAp\", \"PerfectPredictor\", \"TAGE-SC-L\", \"TAGE\", \"Tournament\"],\n",
    "    \"_Core-CoreFrequency_\": [100, 500, 2000, 5000],\n",
    "    \"_DTLB-Size_\": [10, 50, 200, 500],\n",
    "    \"_FloatALU-Latency_\": [1, 5, 10],\n",
    "    \"_FloatMul-Latency_\": [1, 5, 10],\n",
    "    \"_FMA-Latency_\": [1, 5, 10],\n",
    "    \"_IntVectorMul-Latency_\": [1, 5, 10],\n",
    "    \"_ITLB-Size_\": [10, 50, 200, 500],\n",
    "    \"_MainMemory-MainMemoryFrequency_\": [100, 500, 2000, 5000],\n",
    "    \"_MainMemory-MainMemoryLatency_\": [10, 50, 100, 500],\n",
    "}\n",
    "\n",
    "file_names = [x[0]+x[1] for x in list(product(benchmarks, suffixes))]\n",
    "\n",
    "data_struct = {}\n",
    "\n",
    "for s in suffixes:\n",
    "    benchData = {}\n",
    "    for benchmark_name in benchmarks:\n",
    "        grp_data = {}\n",
    "        for i, x in enumerate(size_maps[s]):\n",
    "            try:\n",
    "                with open(base_directory + benchmark_name + s + str(x)+'.json', 'r') as json_file:\n",
    "                    data_dict = json.load(json_file)\n",
    "                    # print(data_dict)\n",
    "            except:\n",
    "                data_dict = None\n",
    "            # print(i)\n",
    "            grp_data[str(x)] = data_dict\n",
    "        benchData[benchmark_name] = grp_data\n",
    "    data_struct[s] = benchData\n",
    "    \n",
    "with open('all_data.json', 'w') as json_file:\n",
    "    json.dump(data_struct, json_file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
