{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks = ['gcc', 'lbm', 'mcf', 'namd', 'xalancbmk']\n",
    "complete_result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_counts(file_path):\n",
    "    counters = {\n",
    "        'mem_inst_retired.any': [], \n",
    "        'branch-instructions': [],\n",
    "        'branch-misses': [], \n",
    "        'L1-icache-load-misses': [], \n",
    "        'L1-dcache-loads': [], \n",
    "        'L1-dcache-load-misses': [], \n",
    "        'L2-loads': [],\n",
    "        'L2-load-misses': [], \n",
    "        'LLC-loads': [], \n",
    "        'LLC-load-misses': [], \n",
    "        'cycles': [], \n",
    "        'instructions': [],\n",
    "    }\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            value, key = line.split()[1:3]\n",
    "            counters[key].append(float(value.replace(',', '')))\n",
    "            \n",
    "    # Sanity Check\n",
    "    lengths = [len(counters[key]) for key in counters]\n",
    "    for i in range(1, len(lengths)):\n",
    "        assert lengths[i] == lengths[i-1]\n",
    "    print(f'Number of Count samples: {lengths[0]}')\n",
    "    return counters\n",
    "\n",
    "def extract_power(file_path):\n",
    "    counters = {\n",
    "        'joule': [], \n",
    "        'time': []\n",
    "    }\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            time, joule = line.split()[0:2]\n",
    "            counters['joule'].append(float(joule))\n",
    "            counters['time'].append(float(time))\n",
    "    \n",
    "    # Sanity Check\n",
    "    lengths = [len(counters[key]) for key in counters]\n",
    "    for i in range(1, len(lengths)):\n",
    "        assert lengths[i] == lengths[i-1]\n",
    "    print(f'Number of Power samples: {lengths[0]}')\n",
    "    return counters\n",
    "\n",
    "def extract_results(counters):\n",
    "    results = {\n",
    "        'IPC': [],\n",
    "        'branch-pred-acc': [],\n",
    "        'L1-cahce-acc': [],\n",
    "        'L2-cache-acc': [],\n",
    "        'L3-cache-acc': [],\n",
    "        'L1-hit-rate': [],\n",
    "        'L2-hit-rate': [],\n",
    "        'L3-hit-rate': [],\n",
    "        'memory-reqs': [],\n",
    "        'power (watt)': [],\n",
    "    }\n",
    "    normal_len = len(counters['instructions'])\n",
    "    for i in range(normal_len):\n",
    "        results['IPC'].append(counters['instructions'][i] / counters['cycles'][i])\n",
    "        results['branch-pred-acc'].append(1 - counters['branch-misses'][i] / counters['branch-instructions'][i])\n",
    "        results['L1-cahce-acc'].append(counters['L1-dcache-loads'][i])\n",
    "        results['L2-cache-acc'].append(counters['L2-loads'][i])\n",
    "        results['L3-cache-acc'].append(counters['LLC-loads'][i])\n",
    "        results['L1-hit-rate'].append(1 - counters['L1-dcache-load-misses'][i] / counters['L1-dcache-loads'][i])\n",
    "        results['L2-hit-rate'].append(1 - counters['L2-load-misses'][i] / counters['L2-loads'][i])\n",
    "        results['L3-hit-rate'].append(1 - counters['LLC-load-misses'][i] / counters['LLC-loads'][i])\n",
    "        L1_hits = counters['L1-dcache-loads'][i] - counters['L1-dcache-load-misses'][i]\n",
    "        L2_hits = counters['L2-loads'][i] - counters['L2-load-misses'][i]\n",
    "        L3_hits = counters['LLC-loads'][i] - counters['LLC-load-misses'][i]\n",
    "        results['memory-reqs'].append(counters['mem_inst_retired.any'][i] - L1_hits - L2_hits - L3_hits)\n",
    "    \n",
    "    power_len = len(counters['joule'])\n",
    "    for i in range(power_len-2):\n",
    "        results['power (watt)'].append(counters['joule'][i] / (counters['time'][i+1] - counters['time'][i]))\n",
    "        \n",
    "    return results\n",
    "\n",
    "def smooth(arr, window):\n",
    "    smoothed = []\n",
    "    for i in range(len(arr)):\n",
    "        left = int(max(0, i - window // 2))\n",
    "        right = int(min(len(arr), i + window // 2 + 1))\n",
    "        window_values = arr[left:right]\n",
    "        smoothed_value = sum(window_values) / len(window_values)\n",
    "        smoothed.append(smoothed_value)\n",
    "    return smoothed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Processing gcc......\n",
      "Number of Count samples: 274\n",
      "Number of Power samples: 280\n",
      "--------------------------\n",
      "Processing lbm......\n",
      "Number of Count samples: 526\n",
      "Number of Power samples: 528\n",
      "--------------------------\n",
      "Processing mcf......\n",
      "Number of Count samples: 238\n",
      "Number of Power samples: 240\n",
      "--------------------------\n",
      "Processing namd......\n",
      "Number of Count samples: 476\n",
      "Number of Power samples: 478\n",
      "--------------------------\n",
      "Processing xalancbmk......\n",
      "Number of Count samples: 1377\n",
      "Number of Power samples: 1351\n"
     ]
    }
   ],
   "source": [
    "for benchmark in benchmarks:\n",
    "    print(\"--------------------------\")\n",
    "    print(f\"Processing {benchmark}......\")\n",
    "    counters = extract_counts(f'./math/{benchmark}-math.count')\n",
    "    power_counters = extract_power(f'./power/{benchmark}-phy.count')\n",
    "    counters.update(power_counters)\n",
    "    complete_result[benchmark] = extract_results(counters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_graphs(metric, smooth_ratio):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for benchmark, result in complete_result.items():\n",
    "        n = len(result[metric])\n",
    "        window = n*smooth_ratio\n",
    "        plt.plot([50*i for i in range(n)], smooth(result[metric], window), label=benchmark)\n",
    "    plt.legend()\n",
    "    plt.title(f\"Plot of {metric} for Different Benchmarks\", fontsize=20)\n",
    "    plt.xlabel(\"Time in (ms)\", fontsize=15)\n",
    "    plt.ylabel(f\"{metric}\", fontsize=15)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/{metric}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in complete_result['gcc'].keys():\n",
    "    plot_and_save_graphs(metric=key, smooth_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
